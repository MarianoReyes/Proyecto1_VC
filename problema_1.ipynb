{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento para eliminar el contorno tipo microscopio de la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./database'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define el directorio donde se encuentran las imágenes y dónde guardarlas\n",
    "input_directory = './database'\n",
    "output_directory = './database'\n",
    "\n",
    "# Crea el directorio de salida si no existe\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Procesa y aplica un umbral a cada imagen\n",
    "for i in range(1, 21):  # Suponiendo que las imágenes están numeradas del 1 al 20\n",
    "    # Construye el nombre de archivo\n",
    "    file_namef = f'{i}.pgm'\n",
    "    file_name = f'{i}'\n",
    "    input_path = os.path.join(input_directory, file_namef)\n",
    "    output_path = os.path.join(output_directory, f'{file_name}_1th.pgm')\n",
    "\n",
    "    # Realiza la misma operación que antes, pero en un bucle para cada imagen\n",
    "    try:\n",
    "        # Carga y convierte la imagen a escala de grises\n",
    "        image = Image.open(input_path).convert(\"L\")\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        # Aplica un umbral\n",
    "        thresholded_np = np.where(image_np < 65, 160, image_np)\n",
    "        thresholded_image = Image.fromarray(thresholded_np.astype(np.uint8))\n",
    "\n",
    "        # Guarda la imagen umbralizada\n",
    "        thresholded_image.save(output_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Archivo {input_path} no encontrado. Saltando.\")\n",
    "\n",
    "# Devuelve la ruta al directorio que contiene las imágenes umbralizadas\n",
    "output_directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarización de Imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen procesada y guardada: 1_2bn.pgm\n",
      "Imagen procesada y guardada: 2_2bn.pgm\n",
      "Imagen procesada y guardada: 3_2bn.pgm\n",
      "Imagen procesada y guardada: 4_2bn.pgm\n",
      "Imagen procesada y guardada: 5_2bn.pgm\n",
      "Imagen procesada y guardada: 6_2bn.pgm\n",
      "Imagen procesada y guardada: 7_2bn.pgm\n",
      "Imagen procesada y guardada: 8_2bn.pgm\n",
      "Imagen procesada y guardada: 9_2bn.pgm\n",
      "Imagen procesada y guardada: 10_2bn.pgm\n",
      "Imagen procesada y guardada: 11_2bn.pgm\n",
      "Imagen procesada y guardada: 12_2bn.pgm\n",
      "Imagen procesada y guardada: 13_2bn.pgm\n",
      "Imagen procesada y guardada: 14_2bn.pgm\n",
      "Imagen procesada y guardada: 15_2bn.pgm\n",
      "Imagen procesada y guardada: 16_2bn.pgm\n",
      "Imagen procesada y guardada: 17_2bn.pgm\n",
      "Imagen procesada y guardada: 18_2bn.pgm\n",
      "Imagen procesada y guardada: 19_2bn.pgm\n",
      "Imagen procesada y guardada: 20_2bn.pgm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def invert_colors(img):\n",
    "    # Invertir los colores de la imagen\n",
    "    return 255 - img\n",
    "\n",
    "def bradley_roth_adaptive_threshold(image, s=15, t=0.07):\n",
    "    # Convertir imagen a escala de grises si es necesario\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "    img = np.array(image, dtype=np.float64)\n",
    "\n",
    "    # Calcular las sumas integrales\n",
    "    integral_img = np.cumsum(np.cumsum(img, axis=1), axis=0)\n",
    "\n",
    "    # Definir tamaño de la ventana\n",
    "    rows, cols = img.shape\n",
    "    s2 = s // 2\n",
    "    result = np.zeros_like(img)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            # Definir límites de la ventana\n",
    "            x1 = max(j - s2, 0)\n",
    "            x2 = min(j + s2, cols - 1)\n",
    "            y1 = max(i - s2, 0)\n",
    "            y2 = min(i + s2, rows - 1)\n",
    "\n",
    "            count = (y2 - y1) * (x2 - x1)\n",
    "            sum_ = integral_img[y2, x2] - integral_img[y1, x2] - integral_img[y2, x1] + integral_img[y1, x1]\n",
    "\n",
    "            if img[i, j] * count <= sum_ * (1 - t):\n",
    "                result[i, j] = 0\n",
    "            else:\n",
    "                result[i, j] = 255\n",
    "\n",
    "    # Invertir colores justo antes de retornar la imagen\n",
    "    result = invert_colors(result)\n",
    "    return Image.fromarray(result.astype(np.uint8))\n",
    "\n",
    "def process_images_in_folder(folder_path):\n",
    "    for i in range(1, 21):  # Suponiendo 20 imágenes\n",
    "        original_path = os.path.join(folder_path, f'{i}_1th.pgm')\n",
    "        \n",
    "        if os.path.exists(original_path):\n",
    "            image = Image.open(original_path)\n",
    "            binarized_image = bradley_roth_adaptive_threshold(image)\n",
    "            binarized_image.save(os.path.join(folder_path, f'{i}_2bn.pgm'))\n",
    "            print(f'Imagen procesada y guardada: {i}_2bn.pgm')\n",
    "        else:\n",
    "            print(f'Imagen no encontrada: {original_path}')\n",
    "\n",
    "# Actualizar con la ruta de tu carpeta\n",
    "folder_path = './database'\n",
    "process_images_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocesamiento de la imagen para eliminar manchas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_median_filter(image_path, output_path, kernel_size=3):\n",
    "    \n",
    "    # Aplica un filtro de medianas a una imagen para eliminar el ruido de sal y pimienta.\n",
    "    \n",
    "    # Cargar la imagen en escala de grises\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    \n",
    "    # Aplicar el filtro de medianas\n",
    "    filtered_image = cv2.medianBlur(image, kernel_size)\n",
    "    \n",
    "    # Guardar la imagen procesada\n",
    "    cv2.imwrite(output_path, filtered_image)\n",
    "\n",
    "\n",
    "output_directory = './database'  # Asegúrate de que este sea el directorio correcto\n",
    "\n",
    "for i in range(1, 21):\n",
    "    input_path = os.path.join(output_directory, f'{i}_2bn.pgm')\n",
    "    output_path = os.path.join(output_directory, f'{i}_3bn_filtered.pgm')\n",
    "    \n",
    "    # Aplica el filtro de medianas con un tamaño de kernel predeterminado\n",
    "    apply_median_filter(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image  | Accuracy  | Sensitivity | Specificity | Precision | F1 Score\n",
      "----------------------------------------------------------------------\n",
      "1      | 0.935     | 0.480       | 0.955       | 0.321     | 0.385  \n",
      "2      | 0.948     | 0.561       | 0.967       | 0.460     | 0.505  \n",
      "3      | 0.946     | 0.495       | 0.965       | 0.384     | 0.432  \n",
      "4      | 0.958     | 0.108       | 0.997       | 0.644     | 0.186  \n",
      "5      | 0.924     | 0.598       | 0.937       | 0.261     | 0.364  \n",
      "6      | 0.940     | 0.707       | 0.949       | 0.345     | 0.463  \n",
      "7      | 0.854     | 0.306       | 0.883       | 0.119     | 0.171  \n",
      "8      | 0.909     | 0.311       | 0.939       | 0.199     | 0.242  \n",
      "9      | 0.926     | 0.648       | 0.941       | 0.370     | 0.471  \n",
      "10     | 0.957     | 0.332       | 0.985       | 0.510     | 0.402  \n",
      "11     | 0.936     | 0.504       | 0.954       | 0.316     | 0.389  \n",
      "12     | 0.956     | 0.624       | 0.984       | 0.773     | 0.691  \n",
      "13     | 0.932     | 0.687       | 0.942       | 0.331     | 0.446  \n",
      "14     | 0.941     | 0.389       | 0.984       | 0.649     | 0.487  \n",
      "15     | 0.972     | 0.704       | 0.985       | 0.712     | 0.708  \n",
      "16     | 0.929     | 0.765       | 0.938       | 0.420     | 0.542  \n",
      "17     | 0.953     | 0.259       | 0.988       | 0.522     | 0.346  \n",
      "18     | 0.951     | 0.301       | 0.987       | 0.554     | 0.390  \n",
      "19     | 0.960     | 0.170       | 0.999       | 0.853     | 0.283  \n",
      "20     | 0.960     | 0.677       | 0.981       | 0.735     | 0.705  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def calculate_metrics(gt, pred):\n",
    "    TP = np.sum((gt == 255) & (pred == 255))\n",
    "    TN = np.sum((gt == 0) & (pred == 0))\n",
    "    FP = np.sum((gt == 0) & (pred == 255))\n",
    "    FN = np.sum((gt == 255) & (pred == 0))\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    f1_score = 2*TP / (2*TP + FP + FN) if (2*TP + FP + FN) != 0 else 0\n",
    "\n",
    "    return accuracy, sensitivity, specificity, precision, f1_score\n",
    "\n",
    "folder_path = './database'\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i in range(1, 21):\n",
    "    gt_path = os.path.join(folder_path, f'{i}_gt.pgm')\n",
    "    bn_path = os.path.join(folder_path, f'{i}_3bn_filtered.pgm')\n",
    "    \n",
    "    if os.path.exists(gt_path) and os.path.exists(bn_path):\n",
    "        gt = cv2.imread(gt_path, 0)\n",
    "        pred = cv2.imread(bn_path, 0)\n",
    "        \n",
    "        metrics.append(calculate_metrics(gt, pred))\n",
    "    else:\n",
    "        metrics.append((None, None, None, None, None))\n",
    "\n",
    "print(\"{:<6} | {:<9} | {:<11} | {:<11} | {:<9} | {:<7}\".format(\"Image\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"Precision\", \"F1 Score\"))\n",
    "print(\"-\" * 70)  # Imprime una línea separadora\n",
    "\n",
    "for i, (accuracy, sensitivity, specificity, precision, f1_score) in enumerate(metrics, 1):\n",
    "    print(\"{:<6} | {:<9.3f} | {:<11.3f} | {:<11.3f} | {:<9.3f} | {:<7.3f}\".format(i, accuracy or 0, sensitivity or 0, specificity or 0, precision or 0, f1_score or 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Accuracy\n",
    "Qué mide: La proporción de predicciones correctas (tanto positivas como negativas) entre el total de casos.\n",
    "Valores buenos: Valores cercanos a 1 (o 100%) son ideales, indicando que la mayoría de las predicciones son correctas.\n",
    "2. Sensitivity (Recall)\n",
    "Qué mide: La proporción de verdaderos positivos identificados correctamente de todos los casos positivos reales.\n",
    "Valores buenos: Valores cercanos a 1 son mejores, lo que significa que el algoritmo es capaz de identificar correctamente la mayoría de los casos positivos reales.\n",
    "3. Specificity\n",
    "Qué mide: La proporción de verdaderos negativos identificados correctamente de todos los casos negativos reales.\n",
    "Valores buenos: Al igual que con la Sensitivity, valores cercanos a 1 son ideales, indicando una alta capacidad para identificar correctamente los casos negativos.\n",
    "4. Precision\n",
    "Qué mide: La proporción de verdaderos positivos sobre el total de positivos predichos (verdaderos positivos + falsos positivos).\n",
    "Valores buenos: Valores más altos (cercanos a 1) son deseables, lo que indica que cuando el modelo predice un caso positivo, es probable que sea correcto.\n",
    "5. F1 Score\n",
    "Qué mide: El promedio armónico de Precision y Sensitivity, ofreciendo un balance entre ambas.\n",
    "Valores buenos: Un F1 Score cercano a 1 es excelente, indicando un equilibrio óptimo entre Precision y Sensitivity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
