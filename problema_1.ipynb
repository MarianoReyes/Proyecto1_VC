{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./database'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define el directorio donde se encuentran las imágenes y dónde guardarlas\n",
    "input_directory = './database'\n",
    "output_directory = './database'\n",
    "\n",
    "# Crea el directorio de salida si no existe\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Procesa y aplica un umbral a cada imagen\n",
    "for i in range(1, 21):  # Suponiendo que las imágenes están numeradas del 1 al 20\n",
    "    # Construye el nombre de archivo\n",
    "    file_namef = f'{i}.pgm'\n",
    "    file_name = f'{i}'\n",
    "    input_path = os.path.join(input_directory, file_namef)\n",
    "    output_path = os.path.join(output_directory, f'{file_name}_th.pgm')\n",
    "\n",
    "    # Realiza la misma operación que antes, pero en un bucle para cada imagen\n",
    "    try:\n",
    "        # Carga y convierte la imagen a escala de grises\n",
    "        image = Image.open(input_path).convert(\"L\")\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        # Aplica un umbral\n",
    "        thresholded_np = np.where(image_np < 65, 250, image_np)\n",
    "        thresholded_image = Image.fromarray(thresholded_np.astype(np.uint8))\n",
    "\n",
    "        # Guarda la imagen umbralizada\n",
    "        thresholded_image.save(output_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Archivo {input_path} no encontrado. Saltando.\")\n",
    "\n",
    "# Devuelve la ruta al directorio que contiene las imágenes umbralizadas\n",
    "output_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen procesada y guardada: 1_bn.pgm\n",
      "Imagen procesada y guardada: 2_bn.pgm\n",
      "Imagen procesada y guardada: 3_bn.pgm\n",
      "Imagen procesada y guardada: 4_bn.pgm\n",
      "Imagen procesada y guardada: 5_bn.pgm\n",
      "Imagen procesada y guardada: 6_bn.pgm\n",
      "Imagen procesada y guardada: 7_bn.pgm\n",
      "Imagen procesada y guardada: 8_bn.pgm\n",
      "Imagen procesada y guardada: 9_bn.pgm\n",
      "Imagen procesada y guardada: 10_bn.pgm\n",
      "Imagen procesada y guardada: 11_bn.pgm\n",
      "Imagen procesada y guardada: 12_bn.pgm\n",
      "Imagen procesada y guardada: 13_bn.pgm\n",
      "Imagen procesada y guardada: 14_bn.pgm\n",
      "Imagen procesada y guardada: 15_bn.pgm\n",
      "Imagen procesada y guardada: 16_bn.pgm\n",
      "Imagen procesada y guardada: 17_bn.pgm\n",
      "Imagen procesada y guardada: 18_bn.pgm\n",
      "Imagen procesada y guardada: 19_bn.pgm\n",
      "Imagen procesada y guardada: 20_bn.pgm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def invert_colors(img):\n",
    "    # Invertir los colores de la imagen\n",
    "    return 255 - img\n",
    "\n",
    "def bradley_roth_adaptive_threshold(image, s=15, t=0.07):\n",
    "    # Convertir imagen a escala de grises si es necesario\n",
    "    if image.mode != 'L':\n",
    "        image = image.convert('L')\n",
    "    img = np.array(image, dtype=np.float64)\n",
    "\n",
    "    # Calcular las sumas integrales\n",
    "    integral_img = np.cumsum(np.cumsum(img, axis=1), axis=0)\n",
    "\n",
    "    # Definir tamaño de la ventana\n",
    "    rows, cols = img.shape\n",
    "    s2 = s // 2\n",
    "    result = np.zeros_like(img)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            # Definir límites de la ventana\n",
    "            x1 = max(j - s2, 0)\n",
    "            x2 = min(j + s2, cols - 1)\n",
    "            y1 = max(i - s2, 0)\n",
    "            y2 = min(i + s2, rows - 1)\n",
    "\n",
    "            count = (y2 - y1) * (x2 - x1)\n",
    "            sum_ = integral_img[y2, x2] - integral_img[y1, x2] - integral_img[y2, x1] + integral_img[y1, x1]\n",
    "\n",
    "            if img[i, j] * count <= sum_ * (1 - t):\n",
    "                result[i, j] = 0\n",
    "            else:\n",
    "                result[i, j] = 255\n",
    "\n",
    "    # Invertir colores justo antes de retornar la imagen\n",
    "    result = invert_colors(result)\n",
    "    return Image.fromarray(result.astype(np.uint8))\n",
    "\n",
    "def process_images_in_folder(folder_path):\n",
    "    for i in range(1, 21):  # Suponiendo 20 imágenes\n",
    "        original_path = os.path.join(folder_path, f'{i}_th.pgm')\n",
    "        \n",
    "        if os.path.exists(original_path):\n",
    "            image = Image.open(original_path)\n",
    "            binarized_image = bradley_roth_adaptive_threshold(image)\n",
    "            binarized_image.save(os.path.join(folder_path, f'{i}_bn.pgm'))\n",
    "            print(f'Imagen procesada y guardada: {i}_bn.pgm')\n",
    "        else:\n",
    "            print(f'Imagen no encontrada: {original_path}')\n",
    "\n",
    "# Actualizar con la ruta de tu carpeta\n",
    "folder_path = './database'\n",
    "process_images_in_folder(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image  | Accuracy  | Sensitivity | Specificity | Precision | F1 Score\n",
      "----------------------------------------------------------------------\n",
      "1      | 0.917     | 0.517       | 0.935       | 0.258     | 0.344  \n",
      "2      | 0.941     | 0.579       | 0.959       | 0.411     | 0.481  \n",
      "3      | 0.938     | 0.516       | 0.957       | 0.343     | 0.412  \n",
      "4      | 0.957     | 0.131       | 0.996       | 0.581     | 0.213  \n",
      "5      | 0.913     | 0.602       | 0.925       | 0.231     | 0.334  \n",
      "6      | 0.930     | 0.725       | 0.938       | 0.306     | 0.430  \n",
      "7      | 0.832     | 0.309       | 0.860       | 0.102     | 0.153  \n",
      "8      | 0.896     | 0.322       | 0.924       | 0.172     | 0.224  \n",
      "9      | 0.908     | 0.657       | 0.922       | 0.311     | 0.422  \n",
      "10     | 0.941     | 0.369       | 0.968       | 0.343     | 0.355  \n",
      "11     | 0.928     | 0.536       | 0.945       | 0.293     | 0.379  \n",
      "12     | 0.947     | 0.639       | 0.974       | 0.677     | 0.657  \n",
      "13     | 0.913     | 0.703       | 0.922       | 0.271     | 0.391  \n",
      "14     | 0.937     | 0.424       | 0.977       | 0.586     | 0.492  \n",
      "15     | 0.967     | 0.707       | 0.981       | 0.656     | 0.680  \n",
      "16     | 0.912     | 0.764       | 0.920       | 0.359     | 0.488  \n",
      "17     | 0.957     | 0.297       | 0.990       | 0.593     | 0.396  \n",
      "18     | 0.952     | 0.360       | 0.984       | 0.548     | 0.435  \n",
      "19     | 0.961     | 0.212       | 0.998       | 0.813     | 0.336  \n",
      "20     | 0.959     | 0.681       | 0.981       | 0.728     | 0.704  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def calculate_metrics(gt, pred):\n",
    "    TP = np.sum((gt == 255) & (pred == 255))\n",
    "    TN = np.sum((gt == 0) & (pred == 0))\n",
    "    FP = np.sum((gt == 0) & (pred == 255))\n",
    "    FN = np.sum((gt == 255) & (pred == 0))\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    f1_score = 2*TP / (2*TP + FP + FN) if (2*TP + FP + FN) != 0 else 0\n",
    "\n",
    "    return accuracy, sensitivity, specificity, precision, f1_score\n",
    "\n",
    "folder_path = './database'\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i in range(1, 21):\n",
    "    gt_path = os.path.join(folder_path, f'{i}_gt.pgm')\n",
    "    bn_path = os.path.join(folder_path, f'{i}_bn.pgm')\n",
    "    \n",
    "    if os.path.exists(gt_path) and os.path.exists(bn_path):\n",
    "        gt = cv2.imread(gt_path, 0)\n",
    "        pred = cv2.imread(bn_path, 0)\n",
    "        \n",
    "        metrics.append(calculate_metrics(gt, pred))\n",
    "    else:\n",
    "        metrics.append((None, None, None, None, None))\n",
    "\n",
    "print(\"{:<6} | {:<9} | {:<11} | {:<11} | {:<9} | {:<7}\".format(\"Image\", \"Accuracy\", \"Sensitivity\", \"Specificity\", \"Precision\", \"F1 Score\"))\n",
    "print(\"-\" * 70)  # Imprime una línea separadora\n",
    "\n",
    "for i, (accuracy, sensitivity, specificity, precision, f1_score) in enumerate(metrics, 1):\n",
    "    print(\"{:<6} | {:<9.3f} | {:<11.3f} | {:<11.3f} | {:<9.3f} | {:<7.3f}\".format(i, accuracy or 0, sensitivity or 0, specificity or 0, precision or 0, f1_score or 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Accuracy\n",
    "Qué mide: La proporción de predicciones correctas (tanto positivas como negativas) entre el total de casos.\n",
    "Valores buenos: Valores cercanos a 1 (o 100%) son ideales, indicando que la mayoría de las predicciones son correctas.\n",
    "2. Sensitivity (Recall)\n",
    "Qué mide: La proporción de verdaderos positivos identificados correctamente de todos los casos positivos reales.\n",
    "Valores buenos: Valores cercanos a 1 son mejores, lo que significa que el algoritmo es capaz de identificar correctamente la mayoría de los casos positivos reales.\n",
    "3. Specificity\n",
    "Qué mide: La proporción de verdaderos negativos identificados correctamente de todos los casos negativos reales.\n",
    "Valores buenos: Al igual que con la Sensitivity, valores cercanos a 1 son ideales, indicando una alta capacidad para identificar correctamente los casos negativos.\n",
    "4. Precision\n",
    "Qué mide: La proporción de verdaderos positivos sobre el total de positivos predichos (verdaderos positivos + falsos positivos).\n",
    "Valores buenos: Valores más altos (cercanos a 1) son deseables, lo que indica que cuando el modelo predice un caso positivo, es probable que sea correcto.\n",
    "5. F1 Score\n",
    "Qué mide: El promedio armónico de Precision y Sensitivity, ofreciendo un balance entre ambas.\n",
    "Valores buenos: Un F1 Score cercano a 1 es excelente, indicando un equilibrio óptimo entre Precision y Sensitivity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
